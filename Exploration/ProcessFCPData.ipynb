{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style('white')\n",
    "plt.set_cmap('gist_gray')\n",
    "\n",
    "\n",
    "# We also install a package to read NiFTI files\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subjects that are under 18 in Baltimore are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Bangor are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Beijing_Zang are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Berlin_Margulies are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Cambridge_Buckner are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Dallas are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in ICBM are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Leiden_2180 are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Leiden_2200 are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Leipzig are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Milwaukee_b are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Munchen are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Newark are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in NewHaven_a are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in NewHaven_b are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Oulu are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Oxford are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in PaloAlto are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Pittsburgh are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Queensland are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in SaintLouis are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in Atlanta are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in AnnArbor_a are:\n",
      "sub16960 13.58\n",
      "sub20317 15.92\n",
      "sub30421 17.58\n",
      "sub38614 14.91\n",
      "sub45660 16.67\n",
      "sub46727 13.83\n",
      "sub49687 13.41\n",
      "sub70106 17.42\n",
      "sub82334 14.92\n",
      "sub86367 15\n",
      "sub87745 14.17\n",
      "sub96621 15.56\n",
      "There are a total of 12 subjects.\n",
      "The subjects that are under 18 in AnnArbor_b are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in NewYork_b are:\n",
      "There are a total of 0 subjects.\n",
      "The subjects that are under 18 in NewYork_a are:\n",
      "sub02503 9.30\n",
      "\n",
      "sub04856 9.27\n",
      "\n",
      "sub15213 16.58\n",
      "\n",
      "sub20732 11.07\n",
      "\n",
      "sub26267 15.92\n",
      "\n",
      "sub28795 10.71\n",
      "\n",
      "sub29935 16.95\n",
      "\n",
      "sub31671 12.02\n",
      "\n",
      "sub38088 16.16\n",
      "\n",
      "sub44979 15.65\n",
      "\n",
      "sub46856 8.82\n",
      "\n",
      "sub54541 7.88\n",
      "\n",
      "sub58313 16.42\n",
      "\n",
      "sub59589 14.61\n",
      "\n",
      "sub61001 13.46\n",
      "\n",
      "sub61241 15.43\n",
      "\n",
      "sub66941 14.59\n",
      "\n",
      "sub70752 15.58\n",
      "\n",
      "sub73490 12.23\n",
      "\n",
      "sub84978 12.68\n",
      "\n",
      "sub88286 15.4\n",
      "\n",
      "sub91196 9.21\n",
      "\n",
      "sub93975 12.73\n",
      "\n",
      "sub96705 13.38\n",
      "\n",
      "sub98061 9.48\n",
      "\n",
      "There are a total of 25 subjects.\n",
      "The subjects that are under 18 in NewYork_a_ADHD are:\n",
      "There are a total of 0 subjects.\n"
     ]
    }
   ],
   "source": [
    "#This part is for figuring out which subjects in the fcp dataset are under 18\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "dir_name = \"../../../../shared/fcp\"\n",
    "fcp_directories = [x for x in os.listdir(dir_name)]\n",
    "for fcp_directory in fcp_directories:\n",
    "    if fcp_directory != \"invalid\" and fcp_directory != \".ipynb_checkpoints\":\n",
    "\n",
    "        filename = dir_name + \"/\" + fcp_directory + \"/\" + fcp_directory + \"_demographics.txt\"\n",
    "\n",
    "        with open(filename) as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "        f = open(filename)\n",
    "        data = f.readlines()\n",
    "        under18_data = []\n",
    "        print(\"The subjects that are under 18 in\",fcp_directory,\"are:\")\n",
    "        for line in data:\n",
    "            data = line.split(\"\\t\")\n",
    "            if fcp_directory == \"NewYork_a\" or fcp_directory == \"NewYork_a_ADHD\":\n",
    "                age = data[3]  \n",
    "            else: \n",
    "                age = data[2]\n",
    "            if float(age) < 18:\n",
    "                under18_data.append(data)\n",
    "                print(data[0],age)\n",
    "        print(\"There are a total of\", len(under18_data),\"subjects.\")\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is for gathering all the skullstripped images in fcp dataset into one giant array\n",
    "from IPython.display import clear_output\n",
    "skullstripped_img_list = []\n",
    "file_id = []\n",
    "sample_size = 0\n",
    "for fcp_directory in fcp_directories:\n",
    "    sub_directories = [x for x in os.listdir(dir_name + \"/\" + fcp_directory) if x.startswith('sub')]\n",
    "    for sub_directory in sub_directories:\n",
    "        anat_directory = [x for x in os.listdir(dir_name + \"/\" + fcp_directory + \"/\" + sub_directory) if x.startswith('anat')]\n",
    "        skullstripped_file_name = dir_name + \"/\" + fcp_directory + \"/\" + sub_directory + '/' + anat_directory[0] + \"/\" + 'mprage_skullstripped.nii.gz'\n",
    "        if os.path.exists(skullstripped_file_name):\n",
    "#             skullstripped_img = nib.load(skullstripped_file_name).get_data()\n",
    "#             skullstripped_img_list.append(skullstripped_img)\n",
    "            file_id.append(sub_directory[3:])\n",
    "            sample_size += 1\n",
    "            clear_output(wait=True)\n",
    "\n",
    "# print(len(skullstripped_img_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146\n"
     ]
    }
   ],
   "source": [
    "# print(skullstripped_img_list[100].shape)\n",
    "print(len(file_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AnnArbor_a_sub04111/', 25.63)\n",
      "[465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916]\n"
     ]
    }
   ],
   "source": [
    "#This block is for finding out which subjects' information is missing in the demographics.csv file\n",
    "#And save only those data where age information is available in the demographics.csv file\n",
    "df = pd.read_csv('../demographics.csv')\n",
    "sheet = df.values\n",
    "filtered = list()\n",
    "for i in range(0, len(sheet)):\n",
    "    if sheet[i, 1]== 'fcp':\n",
    "        filtered.append((sheet[i, 5], sheet[i, 4]))\n",
    "sheet = filtered\n",
    "print(sheet[0])\n",
    "age = []\n",
    "index = list()\n",
    "new_data = []\n",
    "missing = []\n",
    "\n",
    "# for subject in sheet: \n",
    "#     subject_id.append(subject[0][-6:-1])\n",
    "#     subject_age.append(subject[1])\n",
    "# print(len(subject_id),len(subject_age))\n",
    "    \n",
    "    \n",
    "for i in range(0, len(file_id)):\n",
    "    in_sheet = False\n",
    "    for patient in sheet: \n",
    "        if patient[0][-6:-1] == file_id[i]:\n",
    "            age.append(patient[1])\n",
    "            in_sheet = True\n",
    "            break\n",
    "    if not in_sheet:\n",
    "            missing.append(i)\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "print(len(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "onehot_age = list()\n",
    "for i in range(0, len(age)):\n",
    "    current_age = int(round(age[i]))\n",
    "    current_age -= 18\n",
    "    one_hot = [0 for i in range(14)]\n",
    "    if current_age >= 83:\n",
    "        one_hot[-1] = 1\n",
    "    else:\n",
    "        one_hot[current_age // 5] = 1\n",
    "    onehot_age.append(one_hot)\n",
    "print(len(onehot_age))\n",
    "age_class = np.argmax(np.asarray(onehot_age),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'percentage')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(age_class,bins=30, density=True)\n",
    "plt.xlabel('FCP - classes')\n",
    "plt.ylabel('percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1034])\n"
     ]
    }
   ],
   "source": [
    "#Saving three types of labels\n",
    "# age = torch.from_numpy(np.asarray(age))\n",
    "# torch.save(age,\"fcp_ages.pt\")\n",
    "# data = torch.load(\"fcp_ages.pt\")\n",
    "# print(data.shape)\n",
    "\n",
    "# labels_13 = torch.from_numpy(np.asarray(onehot_age))\n",
    "# torch.save(labels_13,\"fcp_labels_13.pt\")\n",
    "# data = torch.load(\"fcp_labels_13.pt\")\n",
    "# print(data.shape)\n",
    "\n",
    "age_class = np.argmax(np.asarray(onehot_age),axis=1)\n",
    "labels_15 = torch.from_numpy(age_class)\n",
    "torch.save(labels_15,\"../../../../data/fcp_labels_14.pt\")\n",
    "data = torch.load(\"../../../../data/fcp_labels_14.pt\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n",
      "torch.Size([1034, 3, 224, 224])\n",
      "torch.Size([1034, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#Make sure all the data in fcp_data have corresponding age labels\n",
    "# fcp_data = torch.load(\"../../fcp_data.pt\")\n",
    "# indices = []\n",
    "# for i in range(fcp_data.shape[0]):\n",
    "#     if i not in missing:\n",
    "#         indices.append(i)\n",
    "# print(len(indices))\n",
    "# new_fcp_data = fcp_data[indices,:]\n",
    "# print(new_fcp_data.shape)\n",
    "\n",
    "# torch.save(new_fcp_data,\"fcp_data.pt\")\n",
    "# data = torch.load(\"fcp_data.pt\")\n",
    "# print(data.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the MRI : torch.Size([1146, 3, 224, 224])\n",
      "torch.Size([1146, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#Slice the most central/important parts of the images (so that they have the same shape) \n",
    "#and convert the array into a tensor\n",
    "import numpy as np\n",
    "new_img_list = []\n",
    "\n",
    "for i in range(len(skullstripped_img_list)):  \n",
    "    d_0 = skullstripped_img_list[i].shape[0]\n",
    "    d_1 = skullstripped_img_list[i].shape[1]\n",
    "    d_2 = skullstripped_img_list[i].shape[2]\n",
    "    new_img = skullstripped_img_list[i][:,int(d_1 / 2),:]\n",
    "    if d_0 > 224:\n",
    "        start_0 = int((d_0 - 224) / 2)\n",
    "        new_img = new_img[start_0:start_0 + 224, :]\n",
    "    else:\n",
    "        if d_0 % 2 == 0:\n",
    "            pad_width = int((224 - d_0) / 2)\n",
    "            new_img = np.pad(np.asarray(new_img),((pad_width, pad_width),(0,0)),\"constant\") \n",
    "        else: \n",
    "            pad_width_0 = int((224 - d_0) / 2)\n",
    "            pad_width_1 = pad_width_0 + 1\n",
    "            new_img = np.pad(np.asarray(new_img),((pad_width_0, pad_width_1),(0,0)),\"constant\") \n",
    "\n",
    "    #modify the dimensions by cropping and zero-padding so that all the images' sizes become 224*224\n",
    "    if d_2 > 224:\n",
    "        start_2 = int((d_2 - 224) / 2)\n",
    "        new_img = new_img[:,start_2:start_2 + 224]\n",
    "    else:\n",
    "        if d_2 % 2 == 0:\n",
    "            pad_width = int((224 - d_2) / 2)\n",
    "            new_img = np.pad(np.asarray(new_img),((0,0),(pad_width, pad_width)),\"constant\") \n",
    "        else: \n",
    "            pad_width_0 = int((224 - d_2) / 2)\n",
    "            pad_width_1 = pad_width_0 + 1\n",
    "            new_img = np.pad(np.asarray(new_img),((0,0),(pad_width_0, pad_width_1)),\"constant\") \n",
    "    final_img = np.tile(new_img,(3,1)).reshape((3,224,224))\n",
    "    new_img_list.append(final_img)    \n",
    "new_img_list = torch.from_numpy(np.asarray(new_img_list))\n",
    "print('Shape of the MRI : {}'.format(new_img_list.shape))\n",
    "\n",
    "#Saves the tensor\n",
    "torch.save(new_img_list,\"fcp_data.pt\")\n",
    "data = torch.load(\"fcp_data.pt\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1146, 3, 224, 224])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
