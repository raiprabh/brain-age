{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n",
      "536\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we plot one slice of the MRI of a subject\n",
    "\n",
    "# We first load the 2 files associated to raw data and segmentation\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#Collect all pre-processed images from .anat directories\n",
    "skullstripped_img_list = []\n",
    "ori_img_list = []\n",
    "seg_img_list = []\n",
    "file_id = []\n",
    "sample_size = 0\n",
    "root_path = \"/shared/ixi-dataset/\"\n",
    "for i in range(19):\n",
    "    dir_name = root_path + \"IXI-T1-\" + str(i)\n",
    "    anat_directories = [x for x in os.listdir(dir_name) if x.endswith('.anat')]\n",
    "    for anat_directory in anat_directories:\n",
    "        ori_file_name = dir_name + '/' + anat_directory + '/T1_biascorr.nii.gz'\n",
    "        seg_file_name = dir_name + '/' + anat_directory + \"/T1_fast_seg.nii.gz\"\n",
    "        if anat_directory[0:3] == 'IXI' and os.path.exists(ori_file_name) and os.path.exists(seg_file_name):\n",
    "            ori_img = nib.load(ori_file_name).get_data()\n",
    "            seg_img = nib.load(seg_file_name).get_data()\n",
    "            skullstripped_img = ori_img * (seg_img > 0)\n",
    "            ori_img_list.append(ori_img)\n",
    "            seg_img_list.append(seg_img)\n",
    "            skullstripped_img = (skullstripped_img - np.mean(skullstripped_img)) / np.std(skullstripped_img)\n",
    "            skullstripped_img_list.append(skullstripped_img)\n",
    "            file_id.append(anat_directory[3:6])\n",
    "            sample_size += 1\n",
    "            clear_output(wait=True)\n",
    "            #print(sample_size)\n",
    "print(len(file_id))\n",
    "print(len(skullstripped_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Resize(size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=SQUEEZENET_MEAN.tolist(),\n",
    "                    std=SQUEEZENET_STD.tolist()),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def deprocess(img, should_rescale=True):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda x: x[0]),\n",
    "        T.Normalize(mean=[0, 0, 0], std=(1.0 / SQUEEZENET_STD).tolist()),\n",
    "        T.Normalize(mean=(-SQUEEZENET_MEAN).tolist(), std=[1, 1, 1]),\n",
    "        T.Lambda(rescale) if should_rescale else T.Lambda(lambda x: x),\n",
    "        T.ToPILImage(),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def rescale(x):\n",
    "    low, high = x.min(), x.max()\n",
    "    x_rescaled = (x - low) / (high - low)\n",
    "    return x_rescaled\n",
    "    \n",
    "def blur_image(X, sigma=1):\n",
    "    X_np = X.cpu().clone().numpy()\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=2)\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=3)\n",
    "    X.copy_(torch.Tensor(X_np).type_as(X))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained SqueezeNet model.\n",
    "# model = torchvision.models.resnet50(pretrained=True)\n",
    "model = torch.load('/model/the_whole_model.pth')\n",
    "# We don't want to train the model, so tell PyTorch not to compute gradients\n",
    "# with respect to model parameters.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# you may see warning regarding initialization deprecated, that's fine, please continue to next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4937, -0.8435, -0.2546,  1.7318, -0.6319],\n",
      "        [ 0.2608, -2.1850, -1.5432,  1.1418, -0.9035],\n",
      "        [-0.6528, -0.7473, -2.5200,  0.1544, -1.2003],\n",
      "        [ 0.0174, -0.7109,  1.5958, -0.4934,  0.9303]])\n",
      "tensor([1, 2, 1, 3])\n",
      "tensor([-0.8435, -1.5432, -0.7473, -0.4934])\n"
     ]
    }
   ],
   "source": [
    "# Example of using gather to select one entry from each row in PyTorch\n",
    "def gather_example():\n",
    "    N, C = 4, 5\n",
    "    s = torch.randn(N, C)\n",
    "    y = torch.LongTensor([1, 2, 1, 3])\n",
    "    print(s)\n",
    "    print(y)\n",
    "    print(s.gather(1, y.view(-1, 1)).squeeze())\n",
    "gather_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    \n",
    "    saliency = None\n",
    "    ##############################################################################\n",
    "    # TODO: Implement this function. Perform a forward and backward pass through #\n",
    "    # the model to compute the gradient of the correct class score with respect  #\n",
    "    # to each input image. You first want to compute the loss over the correct   #\n",
    "    # scores (we'll combine losses across a batch by summing), and then compute  #\n",
    "    # the gradients with a backward pass.                                        #\n",
    "    ##############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    scores = model(X)\n",
    "    loss = torch.sum(scores)\n",
    "    loss.backward()\n",
    "    grads = X.grad\n",
    "    saliency,_ = torch.max(grads.abs(),1)\n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_saliency_maps(X, y):\n",
    "    # Convert X and y from numpy arrays to Torch Tensors\n",
    "    X_tensor = torch.from_numpy(X)\n",
    "    X_tensor = X_tensor.to(device,dtype=dtype)\n",
    "    y = y.to(device,dtype=dtype)\n",
    "#     y_tensor = torch.from_numpy(y)\n",
    "\n",
    "    # Compute saliency maps for images in X\n",
    "    saliency = compute_saliency_maps(X_tensor, y, model)\n",
    "    \n",
    "    s = int(X.shape[2] / 2)\n",
    "    dimension = 2\n",
    "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
    "    # and saliency maps together.\n",
    "    saliency = saliency.cpu().numpy()\n",
    "    N = X.shape[0]\n",
    "    print(N)\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        plt.imshow(X[i].transpose((1,2,0)))\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the MRI : (536, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "new_img_list = []\n",
    "\n",
    "for i in range(len(skullstripped_img_list)):    \n",
    "    new_img = skullstripped_img_list[i][16:240,90,:]\n",
    "    #modify the dimensions by cropping and zero-padding so that all the images' sizes become 224*224\n",
    "    d_2 = new_img.shape[1]\n",
    "    if d_2 % 2 == 0:\n",
    "        pad_width = int((224 - d_2) / 2)\n",
    "        new_img = np.pad(np.asarray(new_img),((0,0),(pad_width, pad_width)),\"constant\") \n",
    "    else: \n",
    "        pad_width_0 = int((224 - d_2) / 2)\n",
    "        pad_width_1 = pad_width_0 + 1\n",
    "        new_img = np.pad(np.asarray(new_img),((0,0),(pad_width_0, pad_width_1)),\"constant\") \n",
    "    final_img = np.tile(new_img,(3,1)).reshape((3,224,224))\n",
    "    new_img_list.append(final_img)    \n",
    "new_img_list = np.asarray(new_img_list)\n",
    "print('Shape of the MRI : {}'.format(new_img_list.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(new_img_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 224, 224)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.load(\"/data/data.pt\")\n",
    "y = torch.load(\"/data/ages.pt\")\n",
    "print(new_img_list[0:2].shape)\n",
    "show_saliency_maps(new_img_list[105:106], y[105:106])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
